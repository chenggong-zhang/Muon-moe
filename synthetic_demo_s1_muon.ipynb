{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "77746e47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from muon import SingleDeviceMuonWithAuxAdam\n",
        "\n",
        "\n",
        "torch.manual_seed(11)\n",
        "np.random.seed(11)\n",
        "random.seed(11)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "52b2cb7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: torch.Size([16000, 1, 200]), test: torch.Size([16000, 1, 200])\n"
          ]
        }
      ],
      "source": [
        "DATA_NUM = 16000\n",
        "CLUSTER_NUM = 4\n",
        "EXPERT_NUM = 8\n",
        "PATCH_NUM = 4\n",
        "PATCH_LEN = 50\n",
        "\n",
        "root = Path(\"synthetic_data_s1\")\n",
        "training_data = torch.load(root / \"train_data.pt\").to(device)\n",
        "training_labels = torch.load(root / \"train_labels.pt\").to(device)\n",
        "test_data = torch.load(root / \"test_data.pt\").to(device)\n",
        "test_labels = torch.load(root / \"test_labels.pt\").to(device)\n",
        "\n",
        "centers = torch.load(root / \"centers.pt\").to(device)\n",
        "features = torch.load(root / \"features.pt\").to(device)\n",
        "\n",
        "with open(root / \"train_cluster\", \"rb\") as fp:\n",
        "    train_cluster_idx = pickle.load(fp)\n",
        "\n",
        "with open(root / \"test_cluster\", \"rb\") as fp:\n",
        "    test_cluster_idx = pickle.load(fp)\n",
        "\n",
        "print(f\"train: {training_data.shape}, test: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "351a04bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def entropy(dispatch):\n",
        "    n_expert = torch.sum(dispatch, dim=0)\n",
        "    n_total = torch.sum(dispatch)\n",
        "    prob = dispatch / n_expert\n",
        "    ent = -torch.nansum(prob * torch.log(prob), dim=0)\n",
        "    return torch.sum((n_expert / n_total) * ent)\n",
        "\n",
        "\n",
        "def top1(t):\n",
        "    values, index = t.topk(k=1, dim=-1)\n",
        "    values, index = map(lambda x: x.squeeze(dim=-1), (values, index))\n",
        "    return values, index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d34b21b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_dim, out_channel, patch_num, small=True, nonlinear=True):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, out_channel * 2, int(input_dim / patch_num), int(input_dim / patch_num))\n",
        "        if small:\n",
        "            self.conv1.weight = nn.Parameter(self.conv1.weight * 0.001)\n",
        "            self.conv1.bias = nn.Parameter(self.conv1.bias * 0.001)\n",
        "        self.out_channel = out_channel\n",
        "        self.nonlinear = nonlinear\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        if self.nonlinear:\n",
        "            x = x ** 3\n",
        "        x = torch.sum(x, 2)\n",
        "        output = torch.stack(\n",
        "            [torch.sum(x[:, : self.out_channel], 1), torch.sum(x[:, self.out_channel :], 1)]\n",
        "        ).transpose(1, 0)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Router(nn.Module):\n",
        "    def __init__(self, input_dim, out_dim, patch_num, noise=True):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, out_dim, int(input_dim / patch_num), int(input_dim / patch_num), bias=False)\n",
        "        self.out_dim = out_dim\n",
        "        self.noise = noise\n",
        "        self.break_tie_noise = torch.normal(0, 1e-5, size=(DATA_NUM, out_dim), device=device)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.weight = nn.Parameter(self.conv1.weight * 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.sum(x, 2)\n",
        "        if self.noise and self.training:\n",
        "            return x + torch.rand(DATA_NUM, self.out_dim, device=device)\n",
        "        if self.training:\n",
        "            return x + self.break_tie_noise\n",
        "        return x\n",
        "\n",
        "\n",
        "class MoE(nn.Module):\n",
        "    def __init__(self, input_dim, out_channel, patch_num, expert_num, strategy=\"top1\", nonlinear=True):\n",
        "        super().__init__()\n",
        "        self.router = Router(input_dim, expert_num, patch_num)\n",
        "        self.models = nn.ModuleList(\n",
        "            [ConvNet(input_dim, out_channel, patch_num, nonlinear=nonlinear) for _ in range(expert_num)]\n",
        "        )\n",
        "        self.strategy = strategy\n",
        "        self.expert_num = expert_num\n",
        "\n",
        "    def forward(self, x):\n",
        "        select = self.router(x)\n",
        "        if self.strategy == \"top1\":\n",
        "            gate, index = top1(select)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only top1 is supported in this notebook.\")\n",
        "\n",
        "        mask = F.one_hot(index, self.expert_num).float()\n",
        "        density = mask.mean(dim=-2)\n",
        "        density_proxy = select.mean(dim=-2)\n",
        "        loss = (density_proxy * density).mean() * float(self.expert_num ** 2)\n",
        "\n",
        "        mask_flat = mask.sum(dim=-1)\n",
        "        combine_tensor = (\n",
        "            gate[..., None, None]\n",
        "            * mask_flat[..., None, None]\n",
        "            * F.one_hot(index, self.expert_num)[..., None]\n",
        "        )\n",
        "        dispatch_tensor = combine_tensor.bool().to(combine_tensor)\n",
        "        expert_inputs = torch.einsum(\"bnd,ben->ebd\", x, dispatch_tensor).unsqueeze(2)\n",
        "\n",
        "        outputs = []\n",
        "        for i in range(self.expert_num):\n",
        "            outputs.append(self.models[i](expert_inputs[i]))\n",
        "\n",
        "        outputs = torch.stack(outputs)\n",
        "        outputs = torch.einsum(\"ijk,jil->il\", combine_tensor, outputs)\n",
        "        outputs = F.softmax(outputs, dim=1)\n",
        "        return outputs, dispatch_tensor, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3988e8d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, criterion, data, labels, optimizers, epochs, load_balancing=True, verbose=True):\n",
        "    entropy_record = []\n",
        "    min_loss = float(\"inf\")\n",
        "    last_select = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for opt in optimizers:\n",
        "            opt.zero_grad()\n",
        "\n",
        "        outputs, select0, load_balancing_loss = model(data)\n",
        "        last_select = select0\n",
        "\n",
        "        counts = torch.stack(\n",
        "            [select0[train_cluster_idx[i]].squeeze(-1).sum(dim=0) for i in range(CLUSTER_NUM)]\n",
        "        )\n",
        "        e = entropy(counts)\n",
        "        entropy_record.append(e)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        if load_balancing:\n",
        "            loss = loss + 0.0001 * load_balancing_loss\n",
        "\n",
        "        if loss.item() <= min_loss:\n",
        "            min_loss = loss.item()\n",
        "        elif loss > min_loss + 0.02:\n",
        "            pass\n",
        "\n",
        "        loss.backward()\n",
        "        for opt in optimizers:\n",
        "            opt.step()\n",
        "\n",
        "        if verbose and epoch % 100 == 0:\n",
        "            print(f\"epoch {epoch}: loss={loss.item():.4f}, entropy={e.item():.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return entropy_record, last_select\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5e135915",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_muon_param_groups(model, lr_muon=0.02, lr_aux=3e-4, weight_decay=0.01, include_router_in_aux=True):\n",
        "    expert_weights = [m.conv1.weight for m in model.models if m.conv1.weight.requires_grad]\n",
        "    aux_params = [m.conv1.bias for m in model.models if m.conv1.bias is not None and m.conv1.bias.requires_grad]\n",
        "    if include_router_in_aux and model.router.conv1.weight.requires_grad:\n",
        "        aux_params.append(model.router.conv1.weight)\n",
        "\n",
        "    groups = []\n",
        "    if expert_weights:\n",
        "        groups.append(dict(params=expert_weights, use_muon=True, lr=lr_muon, weight_decay=weight_decay))\n",
        "    if aux_params:\n",
        "        groups.append(dict(params=aux_params, use_muon=False, lr=lr_aux, betas=(0.9, 0.95), weight_decay=weight_decay))\n",
        "    if not groups:\n",
        "        raise ValueError('No trainable parameters found for Muon/aux groups.')\n",
        "    return groups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ff60cacb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: loss=0.6935, entropy=1.3859\n",
            "epoch 100: loss=0.4847, entropy=1.1620\n",
            "epoch 200: loss=0.4664, entropy=1.0873\n",
            "epoch 300: loss=0.4589, entropy=1.0548\n",
            "epoch 400: loss=0.4605, entropy=1.0330\n",
            "epoch 500: loss=0.4634, entropy=1.0459\n",
            "epoch 600: loss=0.4497, entropy=1.0581\n",
            "Finished Training\n",
            "Overall dispatch counts: tensor([  48, 5080, 2217,  896, 2486, 4237,  843,  193])\n",
            "cluster 0: tensor([   1, 1221,  353,  129,  324, 1986,    7,   14])\n",
            "cluster 1: tensor([  36,  168, 1778,  322,  193, 1007,  495,    0])\n",
            "cluster 2: tensor([   3, 1398,   69,   64,  946, 1199,  297,   30])\n",
            "cluster 3: tensor([   8, 2293,   17,  381, 1023,   45,   44,  149])\n",
            "Accuracy on train (16000 samples): 86.4875%\n",
            "Accuracy on test (16000 samples): 87.0563%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "87.05625"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs = 601\n",
        "\n",
        "# Option A: Muon on expert conv weights, AdamW (aux) on expert biases + router weights in one optimizer\n",
        "model = MoE(200, 8, PATCH_NUM, EXPERT_NUM, strategy=\"top1\", nonlinear=True).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "opt_muon = SingleDeviceMuonWithAuxAdam(make_muon_param_groups(model))\n",
        "entropy_record, select0 = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    training_data,\n",
        "    training_labels,\n",
        "    [opt_muon],\n",
        "    num_epochs,\n",
        "    load_balancing=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print_dispatch(select0)\n",
        "test(model, criterion, training_data, training_labels, name=\"train\")\n",
        "test(model, criterion, test_data, test_labels, name=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7c890c",
      "metadata": {},
      "source": [
        "### Flat expert weights for Muon\n",
        "Flatten experts' conv filters into 2D matrices so Muon can orthogonalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "809baa4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class FlatConvNet(nn.Module):\n",
        "    def __init__(self, input_dim, out_channel, patch_num, small=True, nonlinear=True):\n",
        "        super().__init__()\n",
        "        self.out_channel = out_channel\n",
        "        self.patch_len = int(input_dim / patch_num)\n",
        "        self.weight_flat = nn.Parameter(torch.empty(out_channel * 2, self.patch_len))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channel * 2))\n",
        "        if small:\n",
        "            nn.init.uniform_(self.weight_flat, -1e-3, 1e-3)\n",
        "            nn.init.uniform_(self.bias, -1e-3, 1e-3)\n",
        "        else:\n",
        "            nn.init.xavier_uniform_(self.weight_flat)\n",
        "            nn.init.zeros_(self.bias)\n",
        "        self.nonlinear = nonlinear\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.weight_flat.view(self.out_channel * 2, 1, self.patch_len)\n",
        "        x = F.conv1d(x, w, bias=self.bias, stride=self.patch_len)\n",
        "        if self.nonlinear:\n",
        "            x = x ** 3\n",
        "        x = torch.sum(x, 2)\n",
        "        output = torch.stack([\n",
        "            torch.sum(x[:, : self.out_channel], 1),\n",
        "            torch.sum(x[:, self.out_channel :], 1),\n",
        "        ]).transpose(1, 0)\n",
        "        return output\n",
        "\n",
        "\n",
        "class FlatMoE(nn.Module):\n",
        "    def __init__(self, input_dim, out_channel, patch_num, expert_num, strategy=\"top1\", nonlinear=True):\n",
        "        super().__init__()\n",
        "        self.router = Router(input_dim, expert_num, patch_num)\n",
        "        self.models = nn.ModuleList(\n",
        "            [FlatConvNet(input_dim, out_channel, patch_num, nonlinear=nonlinear) for _ in range(expert_num)]\n",
        "        )\n",
        "        self.strategy = strategy\n",
        "        self.expert_num = expert_num\n",
        "\n",
        "    def forward(self, x):\n",
        "        select = self.router(x)\n",
        "        if self.strategy == \"top1\":\n",
        "            gate, index = top1(select)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only top1 is supported in this notebook.\")\n",
        "\n",
        "        mask = F.one_hot(index, self.expert_num).float()\n",
        "        density = mask.mean(dim=-2)\n",
        "        density_proxy = select.mean(dim=-2)\n",
        "        loss = (density_proxy * density).mean() * float(self.expert_num ** 2)\n",
        "\n",
        "        mask_flat = mask.sum(dim=-1)\n",
        "        combine_tensor = (\n",
        "            gate[..., None, None]\n",
        "            * mask_flat[..., None, None]\n",
        "            * F.one_hot(index, self.expert_num)[..., None]\n",
        "        )\n",
        "        dispatch_tensor = combine_tensor.bool().to(combine_tensor)\n",
        "        expert_inputs = torch.einsum(\"bnd,ben->ebd\", x, dispatch_tensor).unsqueeze(2)\n",
        "\n",
        "        outputs = []\n",
        "        for i in range(self.expert_num):\n",
        "            outputs.append(self.models[i](expert_inputs[i]))\n",
        "\n",
        "        outputs = torch.stack(outputs)\n",
        "        outputs = torch.einsum(\"ijk,jil->il\", combine_tensor, outputs)\n",
        "        outputs = F.softmax(outputs, dim=1)\n",
        "        return outputs, dispatch_tensor, loss\n",
        "\n",
        "\n",
        "def make_flat_muon_param_groups(model, lr_muon=1e-4, lr_aux=3e-4, weight_decay=0.01, include_router_in_aux=True):\n",
        "    expert_weights = [m.weight_flat for m in model.models if m.weight_flat.requires_grad]\n",
        "    aux_params = [m.bias for m in model.models if m.bias is not None and m.bias.requires_grad]\n",
        "    if include_router_in_aux and model.router.conv1.weight.requires_grad:\n",
        "        aux_params.append(model.router.conv1.weight)\n",
        "    groups = []\n",
        "    if expert_weights:\n",
        "        groups.append(dict(params=expert_weights, use_muon=True, lr=lr_muon, weight_decay=weight_decay))\n",
        "    if aux_params:\n",
        "        groups.append(dict(params=aux_params, use_muon=False, lr=lr_aux, betas=(0.9, 0.95), weight_decay=weight_decay))\n",
        "    if not groups:\n",
        "        raise ValueError('No trainable parameters found for Muon/aux groups.')\n",
        "    return groups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "08e687c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: loss=0.6935, entropy=1.3853\n",
            "epoch 100: loss=0.6894, entropy=1.2492\n",
            "epoch 200: loss=0.6157, entropy=0.9963\n",
            "epoch 300: loss=0.5104, entropy=0.8487\n",
            "epoch 400: loss=0.4392, entropy=0.7619\n",
            "epoch 500: loss=0.4057, entropy=0.8015\n",
            "epoch 600: loss=0.3828, entropy=0.8515\n",
            "Finished Training\n",
            "Overall dispatch counts: tensor([2255,  651,  917, 1122, 3459, 1604, 4176, 1816])\n",
            "cluster 0: tensor([ 381,    2,    3,   10,  537,   58, 1411, 1633])\n",
            "cluster 1: tensor([ 393,   15,    1,    2,  281, 1528, 1672,  107])\n",
            "cluster 2: tensor([1047,    0,  908,   55, 1011,   12,  912,   61])\n",
            "cluster 3: tensor([ 434,  634,    5, 1055, 1630,    6,  181,   15])\n",
            "Accuracy on train (16000 samples): 92.8688%\n",
            "Accuracy on test (16000 samples): 92.1813%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "92.18125"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Option C: Flatten expert filters to 2D matrices before Muon\n",
        "num_epochs = 601\n",
        "flat_model = FlatMoE(200, 8, PATCH_NUM, EXPERT_NUM, strategy=\"top1\", nonlinear=True).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "opt_flat_muon = SingleDeviceMuonWithAuxAdam(make_flat_muon_param_groups(flat_model))\n",
        "entropy_record, select0 = train(\n",
        "    flat_model,\n",
        "    criterion,\n",
        "    training_data,\n",
        "    training_labels,\n",
        "    [opt_flat_muon],\n",
        "    num_epochs,\n",
        "    load_balancing=True,\n",
        "    verbose=True,\n",
        ")\n",
        "print_dispatch(select0)\n",
        "test(flat_model, criterion, training_data, training_labels, name=\"train\")\n",
        "test(flat_model, criterion, test_data, test_labels, name=\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "710d80ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: loss=0.6935, entropy=1.3854\n",
            "epoch 100: loss=0.4819, entropy=0.9191\n",
            "epoch 200: loss=0.3537, entropy=0.5482\n",
            "epoch 300: loss=0.3429, entropy=0.6933\n",
            "epoch 400: loss=0.3539, entropy=0.9264\n",
            "epoch 500: loss=0.3644, entropy=1.0911\n",
            "epoch 600: loss=0.3629, entropy=1.1627\n",
            "Finished Training\n",
            "Overall dispatch counts: tensor([2749,  114, 3044,  894,   56, 4351, 1451, 3341])\n",
            "cluster 0: tensor([ 379,    0,  665,    3,    0, 2037,    6,  945])\n",
            "cluster 1: tensor([ 120,    0,  611,  653,    0,  518, 1226,  871])\n",
            "cluster 2: tensor([ 797,  114,  869,   36,    0, 1083,  203,  904])\n",
            "cluster 3: tensor([1453,    0,  899,  202,   56,  713,   16,  621])\n",
            "Accuracy on train-adamw (16000 samples): 95.3187%\n",
            "Accuracy on test-adamw (16000 samples): 94.9562%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.95625"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs = 601\n",
        "\n",
        "flat_model = FlatMoE(200, 8, PATCH_NUM, EXPERT_NUM, strategy=\"top1\", nonlinear=True).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "opt_flat_adamw = torch.optim.AdamW(\n",
        "    flat_model.parameters(), lr=1e-4, betas=(0.9, 0.95), weight_decay=0.01\n",
        ")\n",
        "\n",
        "entropy_record, select0 = train(\n",
        "    flat_model,\n",
        "    criterion,\n",
        "    training_data,\n",
        "    training_labels,\n",
        "    [opt_flat_adamw],   # only AdamW optimizer\n",
        "    num_epochs,\n",
        "    load_balancing=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print_dispatch(select0)\n",
        "test(flat_model, criterion, training_data, training_labels, name=\"train-adamw\")\n",
        "test(flat_model, criterion, test_data, test_labels, name=\"test-adamw\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc96a340",
      "metadata": {},
      "source": [
        "### Compare Muon (flat experts) vs AdamW\n",
        "Runs flat-parameter MoE with Muon+aux AdamW vs all-AdamW and plots test accuracy + dispatch entropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "868444d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "Accuracy on train-muon (16000 samples): 88.5625%\n",
            "Accuracy on test-muon (16000 samples): 87.8375%\n",
            "Finished Training\n",
            "Accuracy on train-adamw (16000 samples): 97.5500%\n",
            "Accuracy on test-adamw (16000 samples): 96.8438%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_flat(mode, epochs=400):\n",
        "    torch.manual_seed(11); np.random.seed(11); random.seed(11)\n",
        "    model = FlatMoE(200, 8, PATCH_NUM, EXPERT_NUM, strategy=\"top1\", nonlinear=True).to(device)\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "    if mode == \"muon\":\n",
        "        opt = SingleDeviceMuonWithAuxAdam(make_flat_muon_param_groups(model, include_router_in_aux=True))\n",
        "        opt_list = [opt]\n",
        "    elif mode == \"adamw\":\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "        opt_list = [opt]\n",
        "    else:\n",
        "        raise ValueError(mode)\n",
        "\n",
        "    entropy_record, select0 = train(model, crit, training_data, training_labels,\n",
        "                                    opt_list, epochs, load_balancing=True, verbose=False)\n",
        "    train_acc = test(model, crit, training_data, training_labels, name=f\"train-{mode}\")\n",
        "    test_acc = test(model, crit, test_data, test_labels, name=f\"test-{mode}\")\n",
        "    return dict(mode=mode, train_acc=train_acc, test_acc=test_acc,\n",
        "                entropy=entropy_record[-1].item(), select0=select0)\n",
        "\n",
        "results = [run_flat(m, epochs=400) for m in [\"muon\", \"adamw\"]]\n",
        "modes = [r[\"mode\"] for r in results]\n",
        "test_acc = [r[\"test_acc\"] for r in results]\n",
        "entropy_vals = [r[\"entropy\"] for r in results]\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax[0].bar(modes, test_acc, color=[\"#377eb8\", \"#984ea3\", \"#4daf4a\"])\n",
        "ax[0].set_title(\"Test Accuracy\"); ax[0].set_ylim(0, 100)\n",
        "ax[1].bar(modes, entropy_vals, color=[\"#377eb8\", \"#984ea3\", \"#4daf4a\"])\n",
        "ax[1].set_title(\"Dispatch Entropy\")\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400e2e6b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "moe",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
